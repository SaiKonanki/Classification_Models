{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11a37f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, classification_report, roc_auc_score, precision_score, recall_score\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, OneHotEncoder, KBinsDiscretizer, PolynomialFeatures, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, classification_report, roc_auc_score, precision_score, recall_score\n",
    "from sklearn.impute import KNNImputer\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import display, HTML\n",
    "from pprint import pprint\n",
    "\n",
    "# Set random seed\n",
    "\"\"\"\n",
    "We fix random seed while creating training and testing data, so that we get the same datasets.\n",
    "\"\"\"\n",
    "np.random.seed(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1106d957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2128d3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12684, 23)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF = pd.read_csv(\"cleaned_df.csv\")\n",
    "Test_DF = DF\n",
    "DF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1302aad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>has_children</th>\n",
       "      <th>toCoupon_GEQ15min</th>\n",
       "      <th>toCoupon_GEQ25min</th>\n",
       "      <th>direction_same</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>temperature</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.019716</td>\n",
       "      <td>-0.155332</td>\n",
       "      <td>-0.216254</td>\n",
       "      <td>0.097085</td>\n",
       "      <td>0.061240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_children</th>\n",
       "      <td>-0.019716</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.078211</td>\n",
       "      <td>-0.013722</td>\n",
       "      <td>-0.031620</td>\n",
       "      <td>-0.045557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toCoupon_GEQ15min</th>\n",
       "      <td>-0.155332</td>\n",
       "      <td>0.078211</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.324984</td>\n",
       "      <td>-0.303533</td>\n",
       "      <td>-0.081602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toCoupon_GEQ25min</th>\n",
       "      <td>-0.216254</td>\n",
       "      <td>-0.013722</td>\n",
       "      <td>0.324984</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.192319</td>\n",
       "      <td>-0.103633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direction_same</th>\n",
       "      <td>0.097085</td>\n",
       "      <td>-0.031620</td>\n",
       "      <td>-0.303533</td>\n",
       "      <td>-0.192319</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>0.061240</td>\n",
       "      <td>-0.045557</td>\n",
       "      <td>-0.081602</td>\n",
       "      <td>-0.103633</td>\n",
       "      <td>0.014570</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   temperature  has_children  toCoupon_GEQ15min  \\\n",
       "temperature           1.000000     -0.019716          -0.155332   \n",
       "has_children         -0.019716      1.000000           0.078211   \n",
       "toCoupon_GEQ15min    -0.155332      0.078211           1.000000   \n",
       "toCoupon_GEQ25min    -0.216254     -0.013722           0.324984   \n",
       "direction_same        0.097085     -0.031620          -0.303533   \n",
       "Y                     0.061240     -0.045557          -0.081602   \n",
       "\n",
       "                   toCoupon_GEQ25min  direction_same         Y  \n",
       "temperature                -0.216254        0.097085  0.061240  \n",
       "has_children               -0.013722       -0.031620 -0.045557  \n",
       "toCoupon_GEQ15min           0.324984       -0.303533 -0.081602  \n",
       "toCoupon_GEQ25min           1.000000       -0.192319 -0.103633  \n",
       "direction_same             -0.192319        1.000000  0.014570  \n",
       "Y                          -0.103633        0.014570  1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the correlation matrix for a dataframe\n",
    "DF.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "35f60366",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12684 entries, 0 to 12683\n",
      "Data columns (total 23 columns):\n",
      " #   Column                Non-Null Count  Dtype   \n",
      "---  ------                --------------  -----   \n",
      " 0   Y                     12684 non-null  int64   \n",
      " 1   destination           12684 non-null  category\n",
      " 2   passanger             12684 non-null  category\n",
      " 3   weather               12684 non-null  category\n",
      " 4   temperature           12684 non-null  int64   \n",
      " 5   time                  12684 non-null  category\n",
      " 6   coupon                12684 non-null  category\n",
      " 7   expiration            12684 non-null  category\n",
      " 8   gender                12684 non-null  category\n",
      " 9   age                   12684 non-null  category\n",
      " 10  maritalStatus         12684 non-null  category\n",
      " 11  has_children          12684 non-null  int64   \n",
      " 12  education             12684 non-null  category\n",
      " 13  occupation            12684 non-null  category\n",
      " 14  income                12684 non-null  category\n",
      " 15  Bar                   12577 non-null  category\n",
      " 16  CoffeeHouse           12467 non-null  category\n",
      " 17  CarryAway             12533 non-null  category\n",
      " 18  RestaurantLessThan20  12554 non-null  category\n",
      " 19  Restaurant20To50      12495 non-null  category\n",
      " 20  toCoupon_GEQ15min     12684 non-null  int64   \n",
      " 21  toCoupon_GEQ25min     12684 non-null  int64   \n",
      " 22  direction_same        12684 non-null  int64   \n",
      "dtypes: category(17), int64(6)\n",
      "memory usage: 809.3 KB\n"
     ]
    }
   ],
   "source": [
    "DF.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59a095a",
   "metadata": {},
   "source": [
    "## Accepting User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4319f410",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Inputs from user\n",
    "\"\"\"\n",
    "\n",
    "# Metric to measure the classification model\n",
    "Metric = 'accuracy' # 'f1' can be used while dealing with imbalanced cases as it can penalize extremities of precision and recall\n",
    "\n",
    "# Target Variable\n",
    "Target = 'Y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c7e0b75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imbalance Ratio of the Target Variable is: 0.43\n"
     ]
    }
   ],
   "source": [
    "# Obtaining imbalance ratio in the target variable\n",
    "\n",
    "Target_Dist = DF[Target].value_counts().tolist()\n",
    "\n",
    "Imbalance_Ratio = (min(Target_Dist)/sum(Target_Dist))\n",
    "\n",
    "print(f\"Imbalance Ratio of the Target Variable is: {Imbalance_Ratio:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90043fa0",
   "metadata": {},
   "source": [
    "## Train and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0c4e9185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12684, 22), (12684,))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separating dependent and independent variables\n",
    "X = DF.drop(labels= Target, axis=1)\n",
    "y = DF.loc[:, Target]\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "58c8323b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "42e4b7a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9513, 22), (3171, 22), (9513,), (3171,))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91be00c7",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e813250d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['temperature',\n",
       " 'has_children',\n",
       " 'toCoupon_GEQ15min',\n",
       " 'toCoupon_GEQ25min',\n",
       " 'direction_same']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "num_cols = list(X.select_dtypes(include = numerics).columns)\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b7b7e79f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['destination',\n",
       " 'passanger',\n",
       " 'weather',\n",
       " 'time',\n",
       " 'coupon',\n",
       " 'expiration',\n",
       " 'gender',\n",
       " 'age',\n",
       " 'maritalStatus',\n",
       " 'education',\n",
       " 'occupation',\n",
       " 'income',\n",
       " 'Bar',\n",
       " 'CoffeeHouse',\n",
       " 'CarryAway',\n",
       " 'RestaurantLessThan20',\n",
       " 'Restaurant20To50']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols = list(X.select_dtypes(include = ['category', 'object']).columns)\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a877b3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building pipeline to automate treatments specific to numeric columns and categorical columns\n",
    "\n",
    "# For numeric, missing values are treated using iterative imputer and data is scaled using robust scaler\n",
    "num_transformer = make_pipeline(IterativeImputer(max_iter=1000, random_state=0),\n",
    "                                RobustScaler())\n",
    "\n",
    "# For cat variables, missing values are imputed with mode and one hot encoder is used to make variable machine readable\n",
    "cat_transformer = make_pipeline(SimpleImputer(strategy= 'most_frequent'),\n",
    "                                OneHotEncoder(handle_unknown='ignore'))\n",
    "\n",
    "# All column transformation operations are put into the column transformer\n",
    "preprocessor = make_column_transformer((num_transformer, num_cols),\n",
    "                                       (cat_transformer, cat_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1547963c",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "20624e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the GridSearchCV is 0.80\n"
     ]
    }
   ],
   "source": [
    "# By using make_pipeline, we 1st preprocess the data and then apply ML algorithm\n",
    "pipelgbm = make_pipeline(preprocessor, LGBMClassifier(), verbose = False)\n",
    "\n",
    "\n",
    "# Grid for hyperparameter tuning\n",
    "lgbm_param_grid = {'lgbmclassifier__num_leaves': [10, 20, 31, 60], # Ideally, number of leaves for LGBM should be less than 2*max_Depth to avoid overfitting\n",
    "#               'lgbmclassifier__min_child_samples': [20, 5, 10],\n",
    "              #'lgbmclassifier__max_depth': [5, 10],\n",
    "#               'lgbmclassifier__learning_rate': [0.05,0.1,0.2], # should not be too high which could cause missing out on patterns in data\n",
    "              'lgbmclassifier__reg_alpha': [0, 0.01]}\n",
    "\n",
    "# If we do not want to do parameter tuning, we can give single options for paramters --- we can keep using this\n",
    "# template for ease of use\n",
    "grid_lgbm = GridSearchCV(pipelgbm,\n",
    "                         param_grid=param_grid,\n",
    "                         cv=3,\n",
    "                         n_jobs=-1, # if -1 uses all cores\n",
    "                         scoring=['accuracy', 'precision', 'recall', 'f1'], # all the different metrics we want to store\n",
    "                         refit = Metric) # metric is given by the user\n",
    "\n",
    "# Fit on train data\n",
    "grid_lgbm.fit(X_train, y_train)\n",
    "\n",
    "# Score on Test data\n",
    "accuracy = grid_lgbm.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(grid_lgbm.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a680d00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:01:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy score of the GridSearchCV is 0.79\n"
     ]
    }
   ],
   "source": [
    "pipexgb = make_pipeline(preprocessor, XGBClassifier(), verbose = False)\n",
    "\n",
    "xgb_param_grid = {\n",
    "       # 'xgbclassifier__min_child_weight': [1, 5, 10],\n",
    "        'xgbclassifier__gamma': [0.5, 1, 1.5, 2, 5],\n",
    "       # 'xgbclassifier__subsample': [0.6, 0.8, 1.0],\n",
    "       # 'xgbclassifier__colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'xgbclassifier__max_depth': [3, 4, 5]\n",
    "        }\n",
    "\n",
    "grid_xgb= GridSearchCV(pipexgb,\n",
    "                         param_grid=xgb_param_grid,\n",
    "                         cv=3,\n",
    "                         n_jobs=-1, # if -1 uses all cores\n",
    "                         scoring=['accuracy', 'precision', 'recall', 'f1'],\n",
    "                         refit = Metric) # metric is given by the user\n",
    "\n",
    "grid_xgb.fit(X_train, y_train)\n",
    "accuracy = grid_xgb.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(grid_xgb.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4b441d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the GridSearchCV is 0.80\n"
     ]
    }
   ],
   "source": [
    "pipe_rf = make_pipeline(preprocessor, RandomForestClassifier(), verbose = False)\n",
    "\n",
    "rf_param_grid = {'randomforestclassifier__n_estimators': [120, 140],'randomforestclassifier__max_depth': [30, 40],\n",
    "                 'randomforestclassifier__min_samples_split': [2, 3],'randomforestclassifier__min_samples_leaf': [3, 5]}\n",
    "\n",
    "grid_rf= GridSearchCV(pipe_rf,\n",
    "                         param_grid=rf_param_grid,\n",
    "                         cv=3,\n",
    "                         n_jobs=-1, # if -1 uses all cores\n",
    "                         scoring=['accuracy', 'precision', 'recall', 'f1'],\n",
    "                         refit = Metric) # metric is given by the user\n",
    "\n",
    "grid_rf.fit(X_train, y_train)\n",
    "accuracy = grid_rf.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(grid_rf.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f054eb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_results(res_dic): # input is a dictionary for all trained models and their score\n",
    "    cv_results =  pd.DataFrame(res_dic)\n",
    "    # first select oly the needed columns\n",
    "    res = cv_results[['params', 'mean_test_f1', 'mean_test_precision', 'mean_test_recall', 'mean_test_accuracy', 'mean_fit_time']]\n",
    "    \n",
    "    # use model_name_extractor to extract and clean the names of the models\n",
    "    def model_name_extractor(col):\n",
    "        # first get the name of the classifier\n",
    "        name = list(col.keys())[0]\n",
    "#         print(name)\n",
    "        \n",
    "        model_name = name.split('__')[0] + '_'\n",
    "#         print(model_name)\n",
    "        # add hyper parameters values in front of the model name andf return it\n",
    "        return model_name + '_'.join([\"%s\" % (  str(v)) for k, v in col.items()])\n",
    "    \n",
    "    \n",
    "    res['params'] = res['params'].apply(model_name_extractor)\n",
    "    \n",
    "    # Rename columns and report the final result\n",
    "    res.rename(columns = {'params' : 'Models',\n",
    "                          'mean_test_f1': 'f1',\n",
    "                          'mean_test_precision': 'Precision',\n",
    "                          'mean_test_recall': 'Recall',\n",
    "                          'mean_test_accuracy': 'Accuracy',\n",
    "                          'mean_fit_time': 'fit time'}, inplace=True)\n",
    "    \n",
    "    # res is a dataframe thats shows all the metrics\n",
    "    res = res.set_index('Models', drop= True)\n",
    "    df_res_sorted = res.sort_values(by = ['f1'], ascending=False) # f1 c\\\n",
    "    return df_res_sorted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "f3431c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>fit time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Models</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>randomforestclassifier_30_3_2_140</th>\n",
       "      <td>0.782806</td>\n",
       "      <td>0.739034</td>\n",
       "      <td>0.832102</td>\n",
       "      <td>0.737517</td>\n",
       "      <td>19.339382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforestclassifier_30_3_2_120</th>\n",
       "      <td>0.782588</td>\n",
       "      <td>0.739252</td>\n",
       "      <td>0.831362</td>\n",
       "      <td>0.737412</td>\n",
       "      <td>15.869275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforestclassifier_30_3_3_140</th>\n",
       "      <td>0.781735</td>\n",
       "      <td>0.736563</td>\n",
       "      <td>0.832841</td>\n",
       "      <td>0.735625</td>\n",
       "      <td>18.617449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforestclassifier_40_3_3_140</th>\n",
       "      <td>0.781626</td>\n",
       "      <td>0.736794</td>\n",
       "      <td>0.832287</td>\n",
       "      <td>0.735625</td>\n",
       "      <td>16.818105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforestclassifier_40_3_2_120</th>\n",
       "      <td>0.781206</td>\n",
       "      <td>0.736535</td>\n",
       "      <td>0.831733</td>\n",
       "      <td>0.735204</td>\n",
       "      <td>14.848599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforestclassifier_30_3_3_120</th>\n",
       "      <td>0.780469</td>\n",
       "      <td>0.735028</td>\n",
       "      <td>0.831916</td>\n",
       "      <td>0.733943</td>\n",
       "      <td>18.842298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforestclassifier_40_3_2_140</th>\n",
       "      <td>0.780370</td>\n",
       "      <td>0.735439</td>\n",
       "      <td>0.831177</td>\n",
       "      <td>0.734048</td>\n",
       "      <td>17.637681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforestclassifier_40_3_3_120</th>\n",
       "      <td>0.779494</td>\n",
       "      <td>0.734086</td>\n",
       "      <td>0.830993</td>\n",
       "      <td>0.732787</td>\n",
       "      <td>14.599129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforestclassifier_30_5_3_140</th>\n",
       "      <td>0.779320</td>\n",
       "      <td>0.732150</td>\n",
       "      <td>0.833026</td>\n",
       "      <td>0.731841</td>\n",
       "      <td>17.742067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforestclassifier_30_5_2_120</th>\n",
       "      <td>0.778446</td>\n",
       "      <td>0.730885</td>\n",
       "      <td>0.832656</td>\n",
       "      <td>0.730579</td>\n",
       "      <td>11.637576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforestclassifier_40_5_3_140</th>\n",
       "      <td>0.777056</td>\n",
       "      <td>0.728874</td>\n",
       "      <td>0.832101</td>\n",
       "      <td>0.728582</td>\n",
       "      <td>13.342126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforestclassifier_40_5_3_120</th>\n",
       "      <td>0.777049</td>\n",
       "      <td>0.730128</td>\n",
       "      <td>0.830438</td>\n",
       "      <td>0.729108</td>\n",
       "      <td>11.798149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforestclassifier_40_5_2_140</th>\n",
       "      <td>0.776920</td>\n",
       "      <td>0.729885</td>\n",
       "      <td>0.830437</td>\n",
       "      <td>0.728897</td>\n",
       "      <td>14.566604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforestclassifier_40_5_2_120</th>\n",
       "      <td>0.776816</td>\n",
       "      <td>0.728851</td>\n",
       "      <td>0.831547</td>\n",
       "      <td>0.728372</td>\n",
       "      <td>12.936000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforestclassifier_30_5_3_120</th>\n",
       "      <td>0.776726</td>\n",
       "      <td>0.729269</td>\n",
       "      <td>0.830807</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>14.327571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforestclassifier_30_5_2_140</th>\n",
       "      <td>0.774329</td>\n",
       "      <td>0.727377</td>\n",
       "      <td>0.827849</td>\n",
       "      <td>0.725744</td>\n",
       "      <td>17.007536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         f1  Precision    Recall  Accuracy  \\\n",
       "Models                                                                       \n",
       "randomforestclassifier_30_3_2_140  0.782806   0.739034  0.832102  0.737517   \n",
       "randomforestclassifier_30_3_2_120  0.782588   0.739252  0.831362  0.737412   \n",
       "randomforestclassifier_30_3_3_140  0.781735   0.736563  0.832841  0.735625   \n",
       "randomforestclassifier_40_3_3_140  0.781626   0.736794  0.832287  0.735625   \n",
       "randomforestclassifier_40_3_2_120  0.781206   0.736535  0.831733  0.735204   \n",
       "randomforestclassifier_30_3_3_120  0.780469   0.735028  0.831916  0.733943   \n",
       "randomforestclassifier_40_3_2_140  0.780370   0.735439  0.831177  0.734048   \n",
       "randomforestclassifier_40_3_3_120  0.779494   0.734086  0.830993  0.732787   \n",
       "randomforestclassifier_30_5_3_140  0.779320   0.732150  0.833026  0.731841   \n",
       "randomforestclassifier_30_5_2_120  0.778446   0.730885  0.832656  0.730579   \n",
       "randomforestclassifier_40_5_3_140  0.777056   0.728874  0.832101  0.728582   \n",
       "randomforestclassifier_40_5_3_120  0.777049   0.730128  0.830438  0.729108   \n",
       "randomforestclassifier_40_5_2_140  0.776920   0.729885  0.830437  0.728897   \n",
       "randomforestclassifier_40_5_2_120  0.776816   0.728851  0.831547  0.728372   \n",
       "randomforestclassifier_30_5_3_120  0.776726   0.729269  0.830807  0.728477   \n",
       "randomforestclassifier_30_5_2_140  0.774329   0.727377  0.827849  0.725744   \n",
       "\n",
       "                                    fit time  \n",
       "Models                                        \n",
       "randomforestclassifier_30_3_2_140  19.339382  \n",
       "randomforestclassifier_30_3_2_120  15.869275  \n",
       "randomforestclassifier_30_3_3_140  18.617449  \n",
       "randomforestclassifier_40_3_3_140  16.818105  \n",
       "randomforestclassifier_40_3_2_120  14.848599  \n",
       "randomforestclassifier_30_3_3_120  18.842298  \n",
       "randomforestclassifier_40_3_2_140  17.637681  \n",
       "randomforestclassifier_40_3_3_120  14.599129  \n",
       "randomforestclassifier_30_5_3_140  17.742067  \n",
       "randomforestclassifier_30_5_2_120  11.637576  \n",
       "randomforestclassifier_40_5_3_140  13.342126  \n",
       "randomforestclassifier_40_5_3_120  11.798149  \n",
       "randomforestclassifier_40_5_2_140  14.566604  \n",
       "randomforestclassifier_40_5_2_120  12.936000  \n",
       "randomforestclassifier_30_5_3_120  14.327571  \n",
       "randomforestclassifier_30_5_2_140  17.007536  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_results(grid_rf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "58664f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the GridSearchCV is 0.75\n"
     ]
    }
   ],
   "source": [
    "pipe_log = make_pipeline(preprocessor, LogisticRegression(), verbose = False)\n",
    "\n",
    "log_param_grid = {\"logisticregression__C\" : np.logspace(-3,3,7), \"logisticregression__penalty\" : [\"l1\",\"l2\"]} # l1 lasso l2 ridge\n",
    "\n",
    "grid_log = GridSearchCV( pipe_log,\n",
    "                         param_grid=log_param_grid,\n",
    "                         cv=3,\n",
    "                         n_jobs=-1, # if -1 uses all cores\n",
    "                         scoring=['accuracy', 'precision', 'recall', 'f1'],\n",
    "                         refit = Metric) # metric is given by the user\n",
    "\n",
    "grid_log.fit(X_train, y_train)\n",
    "accuracy = grid_log.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(grid_log.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "2d4ef4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>fit time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Models</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logisticregression_0.001_l2</th>\n",
       "      <td>0.744066</td>\n",
       "      <td>0.630201</td>\n",
       "      <td>0.908285</td>\n",
       "      <td>0.644802</td>\n",
       "      <td>0.600423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logisticregression_0.01_l2</th>\n",
       "      <td>0.737292</td>\n",
       "      <td>0.689500</td>\n",
       "      <td>0.792348</td>\n",
       "      <td>0.678966</td>\n",
       "      <td>0.353977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logisticregression_0.1_l2</th>\n",
       "      <td>0.734624</td>\n",
       "      <td>0.701984</td>\n",
       "      <td>0.770527</td>\n",
       "      <td>0.683486</td>\n",
       "      <td>0.762945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logisticregression_1.0_l2</th>\n",
       "      <td>0.733622</td>\n",
       "      <td>0.702607</td>\n",
       "      <td>0.767568</td>\n",
       "      <td>0.683065</td>\n",
       "      <td>0.729792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logisticregression_10.0_l2</th>\n",
       "      <td>0.733193</td>\n",
       "      <td>0.702597</td>\n",
       "      <td>0.766643</td>\n",
       "      <td>0.682750</td>\n",
       "      <td>0.726068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logisticregression_100.0_l2</th>\n",
       "      <td>0.732921</td>\n",
       "      <td>0.702568</td>\n",
       "      <td>0.766089</td>\n",
       "      <td>0.682540</td>\n",
       "      <td>0.743577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logisticregression_1000.0_l2</th>\n",
       "      <td>0.732921</td>\n",
       "      <td>0.702568</td>\n",
       "      <td>0.766089</td>\n",
       "      <td>0.682540</td>\n",
       "      <td>0.518670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logisticregression_0.001_l1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.282101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logisticregression_0.01_l1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logisticregression_0.1_l1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.299299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logisticregression_1.0_l1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.359231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logisticregression_10.0_l1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.421175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logisticregression_100.0_l1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.334585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logisticregression_1000.0_l1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.328465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    f1  Precision    Recall  Accuracy  \\\n",
       "Models                                                                  \n",
       "logisticregression_0.001_l2   0.744066   0.630201  0.908285  0.644802   \n",
       "logisticregression_0.01_l2    0.737292   0.689500  0.792348  0.678966   \n",
       "logisticregression_0.1_l2     0.734624   0.701984  0.770527  0.683486   \n",
       "logisticregression_1.0_l2     0.733622   0.702607  0.767568  0.683065   \n",
       "logisticregression_10.0_l2    0.733193   0.702597  0.766643  0.682750   \n",
       "logisticregression_100.0_l2   0.732921   0.702568  0.766089  0.682540   \n",
       "logisticregression_1000.0_l2  0.732921   0.702568  0.766089  0.682540   \n",
       "logisticregression_0.001_l1        NaN        NaN       NaN       NaN   \n",
       "logisticregression_0.01_l1         NaN        NaN       NaN       NaN   \n",
       "logisticregression_0.1_l1          NaN        NaN       NaN       NaN   \n",
       "logisticregression_1.0_l1          NaN        NaN       NaN       NaN   \n",
       "logisticregression_10.0_l1         NaN        NaN       NaN       NaN   \n",
       "logisticregression_100.0_l1        NaN        NaN       NaN       NaN   \n",
       "logisticregression_1000.0_l1       NaN        NaN       NaN       NaN   \n",
       "\n",
       "                              fit time  \n",
       "Models                                  \n",
       "logisticregression_0.001_l2   0.600423  \n",
       "logisticregression_0.01_l2    0.353977  \n",
       "logisticregression_0.1_l2     0.762945  \n",
       "logisticregression_1.0_l2     0.729792  \n",
       "logisticregression_10.0_l2    0.726068  \n",
       "logisticregression_100.0_l2   0.743577  \n",
       "logisticregression_1000.0_l2  0.518670  \n",
       "logisticregression_0.001_l1   0.282101  \n",
       "logisticregression_0.01_l1    0.420760  \n",
       "logisticregression_0.1_l1     0.299299  \n",
       "logisticregression_1.0_l1     0.359231  \n",
       "logisticregression_10.0_l1    0.421175  \n",
       "logisticregression_100.0_l1   0.334585  \n",
       "logisticregression_1000.0_l1  0.328465  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_results(grid_log.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "73d148ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_results_top_2(res_dic):\n",
    "    \"\"\"\n",
    "    This function is used to obtain the top 2 performances of each model\n",
    "    \"\"\"\n",
    "    cv_results =  pd.DataFrame(res_dic)\n",
    "    res = cv_results[['params', 'mean_test_f1', 'mean_test_precision', 'mean_test_recall', 'mean_test_accuracy', 'mean_fit_time']]\n",
    "\n",
    "    def model_name_extractor(col):\n",
    "        name = list(col.keys())[0]\n",
    "        model_name = name.split('__')[0] + '_'\n",
    "        return model_name + '_'.join([\"%s\" % (  str(v)) for k, v in col.items()])\n",
    "    \n",
    "    res['params'] = res['params'].apply(model_name_extractor)\n",
    "    \n",
    "    res.rename(columns = {'params' : 'Models',\n",
    "                          'mean_test_f1': 'f1',\n",
    "                          'mean_test_precision': 'Precision',\n",
    "                          'mean_test_recall': 'Recall',\n",
    "                          'mean_test_accuracy': 'Accuracy',\n",
    "                          'mean_fit_time': 'fit time'}, inplace=True)\n",
    "\n",
    "    res = res.set_index('Models', drop= True)\n",
    "    df_res_sorted = res.sort_values(by = ['f1'], ascending=False)\n",
    "    return df_res_sorted.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "11d1eeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_List = [grid_lgbm, grid_log, grid_xgb, grid_rf]\n",
    "\n",
    "Final_Results = []\n",
    "for i in Model_List:\n",
    "    Temp = clean_results_top_2(i.cv_results_)\n",
    "    Final_Results.append(Temp)\n",
    "    \n",
    "Final_Results = pd.concat(Final_Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "dc3a9e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>fit time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Models</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lgbmclassifier_60_0</th>\n",
       "      <td>0.788342</td>\n",
       "      <td>0.761731</td>\n",
       "      <td>0.816939</td>\n",
       "      <td>0.750657</td>\n",
       "      <td>0.636929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgbmclassifier_60_0.01</th>\n",
       "      <td>0.787829</td>\n",
       "      <td>0.762721</td>\n",
       "      <td>0.814720</td>\n",
       "      <td>0.750552</td>\n",
       "      <td>0.573177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgbclassifier_0.5_5</th>\n",
       "      <td>0.785438</td>\n",
       "      <td>0.759746</td>\n",
       "      <td>0.813056</td>\n",
       "      <td>0.747503</td>\n",
       "      <td>7.315755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgbclassifier_2_5</th>\n",
       "      <td>0.783709</td>\n",
       "      <td>0.757255</td>\n",
       "      <td>0.812316</td>\n",
       "      <td>0.745191</td>\n",
       "      <td>5.469580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforestclassifier_30_3_2_140</th>\n",
       "      <td>0.782806</td>\n",
       "      <td>0.739034</td>\n",
       "      <td>0.832102</td>\n",
       "      <td>0.737517</td>\n",
       "      <td>19.339382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforestclassifier_30_3_2_120</th>\n",
       "      <td>0.782588</td>\n",
       "      <td>0.739252</td>\n",
       "      <td>0.831362</td>\n",
       "      <td>0.737412</td>\n",
       "      <td>15.869275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logisticregression_0.001_l2</th>\n",
       "      <td>0.744066</td>\n",
       "      <td>0.630201</td>\n",
       "      <td>0.908285</td>\n",
       "      <td>0.644802</td>\n",
       "      <td>0.600423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logisticregression_0.01_l2</th>\n",
       "      <td>0.737292</td>\n",
       "      <td>0.689500</td>\n",
       "      <td>0.792348</td>\n",
       "      <td>0.678966</td>\n",
       "      <td>0.353977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         f1  Precision    Recall  Accuracy  \\\n",
       "Models                                                                       \n",
       "lgbmclassifier_60_0                0.788342   0.761731  0.816939  0.750657   \n",
       "lgbmclassifier_60_0.01             0.787829   0.762721  0.814720  0.750552   \n",
       "xgbclassifier_0.5_5                0.785438   0.759746  0.813056  0.747503   \n",
       "xgbclassifier_2_5                  0.783709   0.757255  0.812316  0.745191   \n",
       "randomforestclassifier_30_3_2_140  0.782806   0.739034  0.832102  0.737517   \n",
       "randomforestclassifier_30_3_2_120  0.782588   0.739252  0.831362  0.737412   \n",
       "logisticregression_0.001_l2        0.744066   0.630201  0.908285  0.644802   \n",
       "logisticregression_0.01_l2         0.737292   0.689500  0.792348  0.678966   \n",
       "\n",
       "                                    fit time  \n",
       "Models                                        \n",
       "lgbmclassifier_60_0                 0.636929  \n",
       "lgbmclassifier_60_0.01              0.573177  \n",
       "xgbclassifier_0.5_5                 7.315755  \n",
       "xgbclassifier_2_5                   5.469580  \n",
       "randomforestclassifier_30_3_2_140  19.339382  \n",
       "randomforestclassifier_30_3_2_120  15.869275  \n",
       "logisticregression_0.001_l2         0.600423  \n",
       "logisticregression_0.01_l2          0.353977  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Below we can see the summary of all models and the results\n",
    "Final_Results.sort_values(by = 'f1', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d52825e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing results by pickling the model so that we can reuse the model\n",
    "\n",
    "import pickle\n",
    "file_name = 'LGBM_model_pkl'\n",
    "\n",
    "# create an iterator object with write permission - model.pkl\n",
    "with open(file_name, 'wb') as files:\n",
    "    pickle.dump(grid_lgbm, files)\n",
    "    \n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(file_name, 'rb'))\n",
    "result = loaded_model.score(X_test, y_test)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
